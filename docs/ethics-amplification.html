<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Ethics: Amplification | ML Ethics Wiki</title>
  <meta name="description" content="Chapter 6 Ethics: Amplification | ML Ethics Wiki" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Ethics: Amplification | ML Ethics Wiki" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Ethics: Amplification | ML Ethics Wiki" />
  
  
  

<meta name="author" content="Kyle Jablon" />


<meta name="date" content="2021-04-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ethics-black-box-models.html"/>
<link rel="next" href="sociology-technological-solutionism.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">MLEthics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-problem"><i class="fa fa-check"></i><b>1.1</b> The Problem</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#who-is-this-for"><i class="fa fa-check"></i><b>1.2</b> Who is this for?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#why-do-ethics-matter"><i class="fa fa-check"></i><b>1.3</b> Why do ethics matter?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#why-does-sociology-matter"><i class="fa fa-check"></i><b>1.4</b> Why does sociology matter?</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#why-does-institutionalization-matter"><i class="fa fa-check"></i><b>1.5</b> Why does institutionalization matter?</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#what-is-machine-learning-and-why-is-it-relevant"><i class="fa fa-check"></i><b>1.6</b> What is machine learning and why is it relevant?</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#additional-resources"><i class="fa fa-check"></i><b>1.7</b> Additional Resources</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ethics-dataset-bias-and-its-consequences.html"><a href="ethics-dataset-bias-and-its-consequences.html"><i class="fa fa-check"></i><b>2</b> Ethics: Dataset bias and it’s consequences</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ethics-dataset-bias-and-its-consequences.html"><a href="ethics-dataset-bias-and-its-consequences.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="ethics-dataset-bias-and-its-consequences.html"><a href="ethics-dataset-bias-and-its-consequences.html#the-problem-1"><i class="fa fa-check"></i><b>2.2</b> The problem</a></li>
<li class="chapter" data-level="2.3" data-path="ethics-dataset-bias-and-its-consequences.html"><a href="ethics-dataset-bias-and-its-consequences.html#how-to-identify-the-problem"><i class="fa fa-check"></i><b>2.3</b> How to identify the problem?</a></li>
<li class="chapter" data-level="2.4" data-path="ethics-dataset-bias-and-its-consequences.html"><a href="ethics-dataset-bias-and-its-consequences.html#resources"><i class="fa fa-check"></i><b>2.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ethics-privacy-rights.html"><a href="ethics-privacy-rights.html"><i class="fa fa-check"></i><b>3</b> Ethics: Privacy Rights</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ethics-privacy-rights.html"><a href="ethics-privacy-rights.html#what-do-privacy-rights-have-to-do-with-tech"><i class="fa fa-check"></i><b>3.1</b> What do Privacy Rights have to do with tech?</a></li>
<li class="chapter" data-level="3.2" data-path="ethics-privacy-rights.html"><a href="ethics-privacy-rights.html#what-are-privacy-rights"><i class="fa fa-check"></i><b>3.2</b> What are privacy rights?</a></li>
<li class="chapter" data-level="3.3" data-path="ethics-privacy-rights.html"><a href="ethics-privacy-rights.html#rules-of-thumb"><i class="fa fa-check"></i><b>3.3</b> Rules of thumb</a></li>
<li class="chapter" data-level="3.4" data-path="ethics-privacy-rights.html"><a href="ethics-privacy-rights.html#resources-1"><i class="fa fa-check"></i><b>3.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ethics-environmental-costs-of-machine-learning.html"><a href="ethics-environmental-costs-of-machine-learning.html"><i class="fa fa-check"></i><b>4</b> Ethics: Environmental Costs of Machine Learning</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ethics-environmental-costs-of-machine-learning.html"><a href="ethics-environmental-costs-of-machine-learning.html#the-problem-2"><i class="fa fa-check"></i><b>4.1</b> The Problem</a></li>
<li class="chapter" data-level="4.2" data-path="ethics-environmental-costs-of-machine-learning.html"><a href="ethics-environmental-costs-of-machine-learning.html#how-to-identify-the-problem-1"><i class="fa fa-check"></i><b>4.2</b> How to identify the problem</a></li>
<li class="chapter" data-level="4.3" data-path="ethics-environmental-costs-of-machine-learning.html"><a href="ethics-environmental-costs-of-machine-learning.html#what-can-be-done"><i class="fa fa-check"></i><b>4.3</b> What can be done</a></li>
<li class="chapter" data-level="4.4" data-path="ethics-environmental-costs-of-machine-learning.html"><a href="ethics-environmental-costs-of-machine-learning.html#resources-2"><i class="fa fa-check"></i><b>4.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ethics-black-box-models.html"><a href="ethics-black-box-models.html"><i class="fa fa-check"></i><b>5</b> Ethics: Black Box Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ethics-black-box-models.html"><a href="ethics-black-box-models.html#the-problem-3"><i class="fa fa-check"></i><b>5.1</b> The Problem</a></li>
<li class="chapter" data-level="5.2" data-path="ethics-black-box-models.html"><a href="ethics-black-box-models.html#which-models-are-black-box-models"><i class="fa fa-check"></i><b>5.2</b> Which models are black box models</a></li>
<li class="chapter" data-level="5.3" data-path="ethics-black-box-models.html"><a href="ethics-black-box-models.html#what-can-be-done-1"><i class="fa fa-check"></i><b>5.3</b> What can be done</a></li>
<li class="chapter" data-level="5.4" data-path="ethics-black-box-models.html"><a href="ethics-black-box-models.html#resources-3"><i class="fa fa-check"></i><b>5.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ethics-amplification.html"><a href="ethics-amplification.html"><i class="fa fa-check"></i><b>6</b> Ethics: Amplification</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ethics-amplification.html"><a href="ethics-amplification.html#the-problem-4"><i class="fa fa-check"></i><b>6.1</b> The Problem</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ethics-amplification.html"><a href="ethics-amplification.html#algorithmic-determinism"><i class="fa fa-check"></i><b>6.1.1</b> Algorithmic Determinism</a></li>
<li class="chapter" data-level="6.1.2" data-path="ethics-amplification.html"><a href="ethics-amplification.html#amplifying-misinformation"><i class="fa fa-check"></i><b>6.1.2</b> Amplifying Misinformation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ethics-amplification.html"><a href="ethics-amplification.html#what-can-be-done-2"><i class="fa fa-check"></i><b>6.2</b> What can be done</a></li>
<li class="chapter" data-level="6.3" data-path="ethics-amplification.html"><a href="ethics-amplification.html#resources-4"><i class="fa fa-check"></i><b>6.3</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sociology-technological-solutionism.html"><a href="sociology-technological-solutionism.html"><i class="fa fa-check"></i><b>7</b> Sociology: Technological Solutionism</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sociology-technological-solutionism.html"><a href="sociology-technological-solutionism.html#what-is-technological-solutionism"><i class="fa fa-check"></i><b>7.1</b> What is technological solutionism?</a></li>
<li class="chapter" data-level="7.2" data-path="sociology-technological-solutionism.html"><a href="sociology-technological-solutionism.html#the-problem-5"><i class="fa fa-check"></i><b>7.2</b> The problem</a></li>
<li class="chapter" data-level="7.3" data-path="sociology-technological-solutionism.html"><a href="sociology-technological-solutionism.html#what-can-be-done-3"><i class="fa fa-check"></i><b>7.3</b> What can be done?</a></li>
<li class="chapter" data-level="7.4" data-path="sociology-technological-solutionism.html"><a href="sociology-technological-solutionism.html#resources-5"><i class="fa fa-check"></i><b>7.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="sociology-myths-about-silicon-valley-and-its-workers.html"><a href="sociology-myths-about-silicon-valley-and-its-workers.html"><i class="fa fa-check"></i><b>8</b> Sociology: Myths about Silicon Valley and its Workers</a>
<ul>
<li class="chapter" data-level="8.1" data-path="sociology-myths-about-silicon-valley-and-its-workers.html"><a href="sociology-myths-about-silicon-valley-and-its-workers.html#introduction-2"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="sociology-myths-about-silicon-valley-and-its-workers.html"><a href="sociology-myths-about-silicon-valley-and-its-workers.html#diversity-in-tech-is-a-pipeline-problem"><i class="fa fa-check"></i><b>8.2</b> Diversity in Tech is a “pipeline problem”</a></li>
<li class="chapter" data-level="8.3" data-path="sociology-myths-about-silicon-valley-and-its-workers.html"><a href="sociology-myths-about-silicon-valley-and-its-workers.html#systems-need-to-be-maintained"><i class="fa fa-check"></i><b>8.3</b> Systems need to be maintained</a></li>
<li class="chapter" data-level="8.4" data-path="sociology-myths-about-silicon-valley-and-its-workers.html"><a href="sociology-myths-about-silicon-valley-and-its-workers.html#resources-6"><i class="fa fa-check"></i><b>8.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="law-gdpr.html"><a href="law-gdpr.html"><i class="fa fa-check"></i><b>9</b> Law: GDPR</a>
<ul>
<li class="chapter" data-level="9.1" data-path="law-gdpr.html"><a href="law-gdpr.html#what-is-gdpr"><i class="fa fa-check"></i><b>9.1</b> What is GDPR?</a></li>
<li class="chapter" data-level="9.2" data-path="law-gdpr.html"><a href="law-gdpr.html#what-are-the-current-problems-with-gdpr"><i class="fa fa-check"></i><b>9.2</b> What are the current problems with GDPR?</a></li>
<li class="chapter" data-level="9.3" data-path="law-gdpr.html"><a href="law-gdpr.html#how-is-gdpr-relevant-to-regulation-around-the-world"><i class="fa fa-check"></i><b>9.3</b> How is GDPR relevant to regulation around the world?</a></li>
<li class="chapter" data-level="9.4" data-path="law-gdpr.html"><a href="law-gdpr.html#resources-7"><i class="fa fa-check"></i><b>9.4</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html"><i class="fa fa-check"></i><b>10</b> Law: Regulation in the United States</a>
<ul>
<li class="chapter" data-level="10.1" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#introduction-3"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#the-national-discussion"><i class="fa fa-check"></i><b>10.2</b> The National Discussion</a></li>
<li class="chapter" data-level="10.3" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#california"><i class="fa fa-check"></i><b>10.3</b> California</a></li>
<li class="chapter" data-level="10.4" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#illinois"><i class="fa fa-check"></i><b>10.4</b> Illinois</a></li>
<li class="chapter" data-level="10.5" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#virginia"><i class="fa fa-check"></i><b>10.5</b> Virginia</a></li>
<li class="chapter" data-level="10.6" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#other-states"><i class="fa fa-check"></i><b>10.6</b> Other States</a></li>
<li class="chapter" data-level="10.7" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#conclusion"><i class="fa fa-check"></i><b>10.7</b> Conclusion</a></li>
<li class="chapter" data-level="10.8" data-path="law-regulation-in-the-united-states.html"><a href="law-regulation-in-the-united-states.html#resources-8"><i class="fa fa-check"></i><b>10.8</b> Resources</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="law-the-future-of-regulation.html"><a href="law-the-future-of-regulation.html"><i class="fa fa-check"></i><b>11</b> Law: The future of regulation</a>
<ul>
<li class="chapter" data-level="11.1" data-path="law-the-future-of-regulation.html"><a href="law-the-future-of-regulation.html#introduction-4"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="law-the-future-of-regulation.html"><a href="law-the-future-of-regulation.html#the-problem-6"><i class="fa fa-check"></i><b>11.2</b> The problem</a></li>
<li class="chapter" data-level="11.3" data-path="law-the-future-of-regulation.html"><a href="law-the-future-of-regulation.html#the-long-term-view"><i class="fa fa-check"></i><b>11.3</b> The Long Term View</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ethics-deep-fakes.html"><a href="ethics-deep-fakes.html"><i class="fa fa-check"></i><b>12</b> Ethics: Deep Fakes</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ethics-deep-fakes.html"><a href="ethics-deep-fakes.html#introduction-5"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ethics-deep-fakes.html"><a href="ethics-deep-fakes.html#what-can-be-done-4"><i class="fa fa-check"></i><b>12.2</b> What can be done</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>13</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ML Ethics Wiki</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ethics-amplification" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> Ethics: Amplification</h1>
<div id="the-problem-4" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> The Problem</h2>
<div id="algorithmic-determinism" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Algorithmic Determinism</h3>
<p>The Alleghany County Office of Children Youth and Families runs a system called the Key Information and Demographic System, or KIDS; effectively, this is the part of the local government that deals with issues of child neglect and abuse, and the county uses a risk model called the Allegheny Family Screening Tool (AFST) to forecast child abuse and neglect. This system is outlined by <span class="citation">(<a href="references.html#ref-eubanks2018" role="doc-biblioref">Eubanks 2018</a>)</span>, who notes a multitude of issues with the risk model tooling system, which is essentially a regression. However, the focus here will be on one aspect: the predictive outputs of the model, and the feedback loop that they outline. Ideally, ASFT would predict child maltreatment, but for obvious reasons, measurement is impossible; instead, the system predicts the proxy variables of “community re-referral” where multiple calls are received for the same child within two years, and the proxy variable of “child placement,” when a call results in a child being placed in foster care within two years. As <span class="citation">(<a href="references.html#ref-eubanks2018" role="doc-biblioref">Eubanks 2018</a>)</span> puts it, “the ASFT actually predicts decisions made by the community (which families will be reported to the hotline) and by the agency and the family courts (which children will be removed from their families).” Because of three quarter of cases are actually “child neglect” cases, and the line for neglect can be quite vague, poor families disproportionately get reported for child neglect. This most commonly occurs when parents leave their children at home while they go to work. Once a child gets placed in the system, they are already flagged once, and their risk assessment scores increase. Poor and minority families are more likely to get reported on face. Subsequent referrals thus create a reinforcing cycle, once a report has been made, future risk assessments are more likely to be triggered as problematic risk assessment. This is a case of an algorithmic system constructing a feedback loop, thereby amplifying pre-existing bias that already exists. It has also been called “algorithmic determinism.” However, it is not the only sort of bias that exists.</p>
</div>
<div id="amplifying-misinformation" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Amplifying Misinformation</h3>
<p><span class="citation"><a href="references.html#ref-vosoughi2018" role="doc-biblioref">Vosoughi, Roy, and Aral</a> (<a href="references.html#ref-vosoughi2018" role="doc-biblioref">2018</a>)</span> famously published a paper, titled “The Spread of True and False News Online” which found that false content was 70% more likely to be shared than true content, and that it also takes true stories about six times longer to reach users as for false stories to reach the same number of people. Users receive their news from algorithmically driven social media; these social media organizations optimize for engagement, and at the end of the day false content drives a sense of “novelty” and in turn, greater engagement.</p>
<p>Building on this, <span class="citation">(<a href="references.html#ref-phillips2018" role="doc-biblioref">Phillips 2018</a>)</span> goes one step farther and lays out how the alt-right manipualted journalists, and recommendation systems in order to amplify their message. A small but very vocal group of bad faith actors would begin by manufacturing outrage, and bombarding their victims with abuse on social media. By generating enough outrage, the content would go viral, at which point, mainstream media outlets would cover the the material. Because journalists are inclined to cover both sides of the issue, they cover both conflicting sides. Thus, this mainstream media coverage would result in more users sympathizing with bad faith actors, generating even further mainstream media coverage and amplifying the message even more prominently in society. Building on this, <span class="citation">(<a href="references.html#ref-boyd2017" role="doc-biblioref">Boyd 2017</a>)</span> gives the example of Latanya Sweeney, a computer scientist who searched her own name on google and found a series of advertisements “inviting her to ask if she had a criminal record.” In turn, she ran a series of black and white names through the search engine and found only the black names generated criminal justice results. In the former case, a series of bad faith actors had gamed a series of recommendation engines in order to amplify their message, whereas, in the latter case a search engine learned underlying human biases and amplified the results right back.</p>
<p>What is worth noting though is that this amplification loop is not unique to social media, in essence, it applies to all algorithmically generated content, and recommendation systems. Any recommender system that uses mass user-generated data is vulnerable to this sort of amplification. As <span class="citation">(<a href="references.html#ref-boyd2017" role="doc-biblioref">Boyd 2017</a>)</span> puts it, even if one does their best to try to sanitize a dataset that may contain racialized content or bias, at the end of the day, “no amount of excluding certain subreddits, removing of categories of tweets, or ignoring content with problematic words will prepare you for those who are hellbent on messing with you.”</p>
</div>
</div>
<div id="what-can-be-done-2" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> What can be done</h2>
<p>Unfortunately, amplification is a feature not a bug of large technical systems. Big tech systems are designed to scale, and many machine learning systems are created specifically to enable this scaling. Most systems can eventually be “hacked” in order to amplify problematic content or results, there are even bad actors that bank on it. That being said, documentation, an open door policy, stress testing and early detection are key.</p>
<p>Race and socioeconomic should be warily used as inputs for algorithmic models, nor should data that functions as a proxy for race and socioeconomic status (zip code, high school). These inputs have the potential to amplify existing inequality trends, and create deterministic output based on the inputs.</p>
<p>Brainstorming sources of bias is a helpful intellectual exercise to explore the possibilities of misuse of any AI system. This can be done with a handful of practitioners where they brainstorm and note possible sources of bias that could be both introduced and amplified in their machine learning system. Once the brainstorming is completed, noting possible results in any model documentation is integral to see if these issues crop up again. In a more structured manner, <span class="citation">(<a href="references.html#ref-mitchell2019" role="doc-biblioref">Mitchell et al., n.d.</a>)</span> has suggested utilizing model cards for all productionized machine learning models. One component of these are impact analyses.</p>
<p>Acceptance testing is integral in any technical product being built. For machine learning models in particular, creating extreme sample data in order to run “sanity tests” on the resulting machine learning model being implemented is integral. This sample data can be derived from existing sample data, but with artificial changes in specific columns relating to race, or geolocation. This provides an straightforward mechanism to stress test an algorithmic system for possible amplification bias.</p>
</div>
<div id="resources-4" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Resources</h2>
<p><strong>An article to read: </strong>
<strong>A story to read: </strong></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ethics-black-box-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sociology-technological-solutionism.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-amplification.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/kylej1994/ml_ethics_wiki/blob/master/07-amplification.Rmd",
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
